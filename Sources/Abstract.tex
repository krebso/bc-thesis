\chapter*{Abstract}

RationAI group trained a convolutional neural network model that can reliably predict the presence of prostate cancer in digitized tissue samples.
Our goal is to find an explainability method to help us understand those predictions in a reasonable time.
We review several popular explainability methods that produce visually similar results to the current, notably slow solution based on Occlusion.
To ensure the suitability of our candidate methods, we carefully establish an exhaustive quantitative benchmark and present our results to a domain expert.
Our evaluated methods achieve $2$ orders of magnitude faster computation time and $50$ times better GPU utilization without sacrificing their faithfulness or localization capabilities.
Furthermore, a domain expert considers two methods as viable alternatives.
Including all auxiliary RationAI's pipeline processing, the methods selected as suitable allow us to generate explanations for a dataset of 87 Whole Slide Images in about $2$ hours, compared to the $3.3$ days needed using Occlusion.

\section*{Keywords}
digital histopathology, convolutional neural networks, explainable artificial intelligence, occlusion, CAM, HiResCAM, performance, faithfulness, localization
