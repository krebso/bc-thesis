\chapter{Introduction}\label{chap:introduction}

With deep learning and neural networks in the spotlight of contemporary research, we see their assimilation in a wide range of fields.

However, in places where the capabilities of deep learning models could help the most, deployed neural networks suffer from their ``black box'' tag and the lack of direct insight behind their decisions. In such critical areas as medicine, quantitative trading, or law, it is essential to have an accurate proxy to shed light on the model's decision process. 

This thesis aims to find methods suitable for such reasoning.
Occlusion, a faithful method tested by Gallo et al. \cite{gallo}, is too slow to be used in real-time.
Thus, we begin our search for a faster method that does not compromise the usability and faithfulness of its explanations.

To find such a method, we need to understand our domain and its limitations.
Therefore, we start with an overview of essential concepts and nomenclature related to pathology and deep learning, with a focus on prostate cancer detection and a model trained by the RationAI group.
We then motivate the need for such an explanatory proxy and review several well-established methods, carefully selected based on previous work of the~RationAI group in  \cite{gallo, bajger-grad-cam, krajnansky-grad-cam, hruska-grad-cam}.
To verify the suitability of the reviewed methods, we evaluate them against a bespoke quantitative benchmark --- ensuring that the methods are both faithful proxies and communicate concepts relevant to a human domain expert.
Afterward, we consult our results and verify the aptness of two well-performing methods with a pathologist who has prior experience with the explanations generated by Occlusion and has participated in \cite{gallo}.
